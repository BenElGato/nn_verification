## Results for Setting 1
![Average Rewards Plot](/home/benedikt/PycharmProjects/nn_verification/pendelum/neural_network/network_code/PPO/training_docs/entropy/graph1.png)

{'neurons': 9, 'timesteps_per_batch': 2048, 'max_timesteps_per_episode': 200, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'dynamic_lr': True, 'lr': 0.003, 'clip': 0.3, 'entropy_coef': 0.0, 'gradient_clipping': False, 'max_grad_norm': 0.5, 'total_timesteps': 1000000}

## Results for Setting 2
![Average Rewards Plot](/home/benedikt/PycharmProjects/nn_verification/pendelum/neural_network/network_code/PPO/training_docs/entropy/graph2.png)

{'neurons': 9, 'timesteps_per_batch': 2048, 'max_timesteps_per_episode': 200, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'dynamic_lr': True, 'lr': 0.003, 'clip': 0.3, 'entropy_coef': 0.1, 'gradient_clipping': False, 'max_grad_norm': 0.5, 'total_timesteps': 1000000}

## Results for Setting 3
![Average Rewards Plot](/home/benedikt/PycharmProjects/nn_verification/pendelum/neural_network/network_code/PPO/training_docs/entropy/graph3.png)

{'neurons': 9, 'timesteps_per_batch': 2048, 'max_timesteps_per_episode': 200, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'dynamic_lr': True, 'lr': 0.003, 'clip': 0.3, 'entropy_coef': 0.2, 'gradient_clipping': False, 'max_grad_norm': 0.5, 'total_timesteps': 1000000}

## Results for Setting 4
![Average Rewards Plot](/home/benedikt/PycharmProjects/nn_verification/pendelum/neural_network/network_code/PPO/training_docs/entropy/graph4.png)

{'neurons': 9, 'timesteps_per_batch': 2048, 'max_timesteps_per_episode': 200, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'dynamic_lr': True, 'lr': 0.003, 'clip': 0.3, 'entropy_coef': 0.3, 'gradient_clipping': False, 'max_grad_norm': 0.5, 'total_timesteps': 1000000}

## Results for Setting 5
![Average Rewards Plot](/home/benedikt/PycharmProjects/nn_verification/pendelum/neural_network/network_code/PPO/training_docs/entropy/graph5.png)

{'neurons': 9, 'timesteps_per_batch': 2048, 'max_timesteps_per_episode': 200, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'dynamic_lr': True, 'lr': 0.003, 'clip': 0.3, 'entropy_coef': 0.4, 'gradient_clipping': False, 'max_grad_norm': 0.5, 'total_timesteps': 1000000}

## Results for Setting 6
![Average Rewards Plot](/home/benedikt/PycharmProjects/nn_verification/pendelum/neural_network/network_code/PPO/training_docs/entropy/graph6.png)

{'neurons': 9, 'timesteps_per_batch': 2048, 'max_timesteps_per_episode': 200, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'dynamic_lr': True, 'lr': 0.003, 'clip': 0.3, 'entropy_coef': 0.5, 'gradient_clipping': False, 'max_grad_norm': 0.5, 'total_timesteps': 1000000}

## Results for Setting 7
![Average Rewards Plot](/home/benedikt/PycharmProjects/nn_verification/pendelum/neural_network/network_code/PPO/training_docs/entropy/graph7.png)

{'neurons': 9, 'timesteps_per_batch': 2048, 'max_timesteps_per_episode': 200, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'dynamic_lr': True, 'lr': 0.003, 'clip': 0.3, 'entropy_coef': 0.6, 'gradient_clipping': False, 'max_grad_norm': 0.5, 'total_timesteps': 1000000}

## Results for Setting 8
![Average Rewards Plot](/home/benedikt/PycharmProjects/nn_verification/pendelum/neural_network/network_code/PPO/training_docs/entropy/graph8.png)

{'neurons': 9, 'timesteps_per_batch': 2048, 'max_timesteps_per_episode': 200, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'dynamic_lr': True, 'lr': 0.003, 'clip': 0.3, 'entropy_coef': 0.7, 'gradient_clipping': False, 'max_grad_norm': 0.5, 'total_timesteps': 1000000}

## Results for Setting 9
![Average Rewards Plot](/home/benedikt/PycharmProjects/nn_verification/pendelum/neural_network/network_code/PPO/training_docs/entropy/graph9.png)

{'neurons': 9, 'timesteps_per_batch': 2048, 'max_timesteps_per_episode': 200, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'dynamic_lr': True, 'lr': 0.003, 'clip': 0.3, 'entropy_coef': 0.8, 'gradient_clipping': False, 'max_grad_norm': 0.5, 'total_timesteps': 1000000}

